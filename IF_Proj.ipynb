{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "806245d5a40843d79de75aa41e6b33a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56aa0e4ebef04967b931fff799deb609",
              "IPY_MODEL_f61284fce6fb4395b89553b7b2e77cf5",
              "IPY_MODEL_b8eef09c18b64eb98bdb101888dd2a85"
            ],
            "layout": "IPY_MODEL_bf965112b4b4410ba49c9d24e4fa08bf"
          }
        },
        "56aa0e4ebef04967b931fff799deb609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76c4e6b61cf41e4a3deb816ae35daed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e0933e9de10470188679cefa9585f34",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=16):â€‡100%"
          }
        },
        "f61284fce6fb4395b89553b7b2e77cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca96ff189ca4bdc8db84bb86b62a5f1",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe7e350f493344c989f7dcd8a06f9871",
            "value": 500
          }
        },
        "b8eef09c18b64eb98bdb101888dd2a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683ba52a06a64918bbb2c6d255fe0a45",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_efd97cf50a5e4dcba1ba85e36251d5fd",
            "value": "â€‡500/500â€‡[00:01&lt;00:00,â€‡642.32â€‡examples/s]"
          }
        },
        "bf965112b4b4410ba49c9d24e4fa08bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76c4e6b61cf41e4a3deb816ae35daed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0933e9de10470188679cefa9585f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ca96ff189ca4bdc8db84bb86b62a5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7e350f493344c989f7dcd8a06f9871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683ba52a06a64918bbb2c6d255fe0a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd97cf50a5e4dcba1ba85e36251d5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n"
      ],
      "metadata": {
        "id": "65dfIrGhMIav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, re, random\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "PO92YCVXBiUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n"
      ],
      "metadata": {
        "id": "D9tOpB3AMPfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"INK-USC/riddle_sense\", split=\"train\", trust_remote_code=True)\n",
        "ansKey = {'A':0,'B':1,'C':2,'D':3,'E':4}"
      ],
      "metadata": {
        "id": "WRByWGDNqYXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3965593-3242-4c97-e1e1-dbf98543921e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['question'][0])\n",
        "print(dataset['answerKey'][0])\n",
        "print(dataset['choices'][0]['text'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUE7eQx7rweA",
        "outputId": "d8102213-013e-40e2-87b2-dadc4f8a0b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter?\n",
            "E\n",
            "hole\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getExample():\n",
        "  rndm = random.randint(501, 3510)\n",
        "  shot = \"Riddle: \" + dataset['question'][rndm] + \"\\n\"\n",
        "  ans = dataset['answerKey'][rndm]\n",
        "  shot += \"Answer: \" + dataset['choices'][rndm]['text'][ansKey[ans]]\n",
        "  return shot\n",
        "\n",
        "print(getExample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsq5Eo8VtHXJ",
        "outputId": "16bd49f6-60ca-48af-f4a2-54e921de0fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Riddle: 1 man runs 3 blocks and then comes home and there is 2 maced men who r they?\n",
            "Answer: catcher and umpier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "r1kO6265MQu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code from https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-v0.3\",\n",
        "    max_seq_length = 4096, # Choose any!\n",
        "    dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "    load_in_4bit = True, # Use 4bit quantization to reduce memory usage. Can be False.\n",
        ")\n",
        "EOS_TOKEN = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYJxXgp7CcUz",
        "outputId": "26b89874-ae34-44cf-df90-b0d7c8266036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth: Could not import trl.trainer.alignprop_trainer: Failed to import trl.trainer.alignprop_trainer because of the following error (look up to see its traceback):\n",
            "Failed to import trl.models.modeling_sd_base because of the following error (look up to see its traceback):\n",
            "Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\n",
            "Failed to import diffusers.loaders.ip_adapter because of the following error (look up to see its traceback):\n",
            "JITCallable._set_src() takes 1 positional argument but 2 were given\n",
            "Unsloth: Could not import trl.trainer.ddpo_trainer: Failed to import trl.trainer.ddpo_trainer because of the following error (look up to see its traceback):\n",
            "Failed to import trl.models.modeling_sd_base because of the following error (look up to see its traceback):\n",
            "Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\n",
            "Failed to import diffusers.loaders.ip_adapter because of the following error (look up to see its traceback):\n",
            "JITCallable._set_src() takes 1 positional argument but 2 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unsloth_zoo.log:Unsloth: Failed to import trl openenv: No module named 'trl.experimental'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.4: Fast Mistral patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"mistral\",\n",
        "    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n",
        "    map_eos_token = True, # Maps <|im_end|> to </s> instead\n",
        ")\n",
        "\n",
        "#FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ],
      "metadata": {
        "id": "pHLcx-yQHy9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINETUNING"
      ],
      "metadata": {
        "id": "wyfGVF8xBamm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindataset = load_dataset(\"INK-USC/riddle_sense\", split=\"train[:500]\", trust_remote_code=True)\n",
        "traindataset = traindataset.map(lambda example, idx: {\"question\": 'Riddle: '+ example[\"question\"] + '\\nAnswer: ' + example[\"choices\"]['text'][ansKey[example['answerKey']]] + EOS_TOKEN}, with_indices=True)\n",
        "traindataset = traindataset.map(remove_columns=['choices','answerKey'])\n",
        "print(traindataset['question'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTA9kwCTkkVW",
        "outputId": "5a0db88b-b501-420a-867b-7e71e5a9d136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Riddle: A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter?\n",
            "Answer: hole</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "\n",
        "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0.01, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dI_tGKzqLdo",
        "outputId": "97641354-2025-4fd9-bf3a-78d5a15c1190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.01.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
            "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:1222: UserWarning: Model has `tie_word_embeddings=True` and a tied layer is part of the adapter, but `ensure_weight_tying` is not set to True. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. Check the discussion here: https://github.com/huggingface/peft/issues/2777\n",
            "  warnings.warn(msg)\n",
            "Unsloth 2025.12.4 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
            "Unsloth: Training lm_head in mixed precision to save VRAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"question\"]\n",
        "    texts = []\n",
        "    for instruction in instructions:\n",
        "        # The 'question' field already contains the formatted riddle and answer\n",
        "        text = f\"{instruction}\"\n",
        "        texts.append(text)\n",
        "    return texts # Changed to return the list directly\n",
        "\n",
        "trainer = UnslothTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = traindataset,\n",
        "    #ataset_text_field = \"question\", # Remove this line as formatting_func will handle it\n",
        "    max_seq_length = 4096,\n",
        "    dataset_num_proc = 8,\n",
        "    formatting_func = formatting_prompts_func,\n",
        "\n",
        "    args = UnslothTrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 8,\n",
        "        gradient_checkpointing=True,\n",
        "\n",
        "        warmup_ratio = 0.1,\n",
        "        num_train_epochs = 1,\n",
        "\n",
        "        learning_rate = 5e-5,\n",
        "        embedding_learning_rate = 5e-6,\n",
        "\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.00,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "806245d5a40843d79de75aa41e6b33a9",
            "56aa0e4ebef04967b931fff799deb609",
            "f61284fce6fb4395b89553b7b2e77cf5",
            "b8eef09c18b64eb98bdb101888dd2a85",
            "bf965112b4b4410ba49c9d24e4fa08bf",
            "d76c4e6b61cf41e4a3deb816ae35daed",
            "2e0933e9de10470188679cefa9585f34",
            "7ca96ff189ca4bdc8db84bb86b62a5f1",
            "fe7e350f493344c989f7dcd8a06f9871",
            "683ba52a06a64918bbb2c6d255fe0a45",
            "efd97cf50a5e4dcba1ba85e36251d5fd"
          ]
        },
        "id": "OGq7H0mUUFZ0",
        "outputId": "ddc3548a-1d43-4a8f-c8c8-f0b9db289fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trl.trainer.sft_trainer:Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "806245d5a40843d79de75aa41e6b33a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Padding-free auto-enabled, enabling faster training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E5lOIBbjdFrM",
        "outputId": "acc6d8a8-448c-42c4-b354-5f2bd353c1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 32\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 603,979,776 of 7,852,003,328 (7.69% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 02:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.374700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.816800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.959500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.277200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.639300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.206400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.283600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.314800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.086200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.256200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.123800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.298200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>2.298900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.220900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.452200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>2.554900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.294600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.158400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.988500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.192200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>2.203900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.778200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to prompt the model"
      ],
      "metadata": {
        "id": "AriPpOXVxQG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def promptMinstral(myprompt):\n",
        "  messages = [{\"from\":\"human\", \"value\": myprompt}]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      tokenize = True,\n",
        "      add_generation_prompt = True, # Must add for generation\n",
        "      return_tensors = \"pt\",\n",
        "  ).to(\"cuda\")\n",
        "  outputs = model.generate(input_ids = inputs, max_new_tokens = 128, use_cache = True)\n",
        "  return tokenizer.batch_decode(outputs)[0]"
      ],
      "metadata": {
        "id": "qqelLuW9BtTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regex"
      ],
      "metadata": {
        "id": "7v_1XED53AYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "def decodeOutput(riddle):\n",
        "  decoded = re.split(r\"\\[/INST\\]\",riddle)\n",
        "  decoded = decoded[1] # cuts off prompt\n",
        "\n",
        "  riddle = re.search(\"[r|R]iddle: (.*)(<)+?\", decoded)\n",
        "  if not riddle:\n",
        "    riddlesplit = decoded.split('\\n')\n",
        "    riddle = riddlesplit[0] if len(riddlesplit[0]) > 1 else riddlesplit[1]\n",
        "    if '<' in riddle:\n",
        "      riddle = riddle.split('<')[0]\n",
        "  else:\n",
        "    riddle = riddle[1]\n",
        "\n",
        "  answer = re.search(\"[a|A]nswer: (.*)(<)+?\", decoded)\n",
        "  if not answer:\n",
        "    answer = \"None\"\n",
        "  else:\n",
        "    answer = answer[1]\n",
        "\n",
        "  if answer == \"None\" and not riddle:\n",
        "    print(decoded)\n",
        "  return riddle, answer"
      ],
      "metadata": {
        "id": "5EbwULo13Ch_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#myInput = \"\"\"Your job is to generate a riddle given another riddle. Only send the riddle and answer. Following is an example of a riddle you should emulate. Example: \"\"\" + getExample()\n",
        "#myInput = \"\"\"You're a specialist in creating riddles. You always format the riddle following the example, putting the riddle and answer on one line each:\\\"\"\"\" + getExample() + \"\\\"\\nNow its your turn. Create a riddle.\"\n",
        "myInput = \"\"\"Your job is to generate a riddle given another riddle. Only send the riddle and answer. Following is an example of a riddle you should emulate. Example: \\n\"\"\" + getExample()\n",
        "\n",
        "rawOutput = promptMinstral(myInput)\n",
        "\n",
        "print(rawOutput)\n",
        "print(\"---------------------------\\n\")\n",
        "\n",
        "riddle, answer = decodeOutput(rawOutput)\n",
        "print(riddle, answer)"
      ],
      "metadata": {
        "id": "jZZyU4o63vZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965ce0cf-f2d4-44d2-a1ba-29e4427e0625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Your job is to generate a riddle given another riddle. Only send the riddle and answer. Following is an example of a riddle you should emulate. Example: \n",
            "Riddle: you ride into a town on wednesday,you stay three days and leave on wednesday.   how is that possible?\n",
            "Answer: your horses name is wednesday [/INST]: you ride into a town on wednesday,you stay three days and leave on wednesday.   how is that possible?\n",
            "Answer: your horses name is wednesday</s>\n",
            "---------------------------\n",
            "\n",
            ": you ride into a town on wednesday,you stay three days and leave on wednesday.   how is that possible? your horses name is wednesday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Location nodes and map"
      ],
      "metadata": {
        "id": "vszVyitCP-EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Location:\n",
        "  def __init__(self, block = False):\n",
        "    self.blocked = block\n",
        "    # room connections\n",
        "    self.north = None\n",
        "    self.east = None\n",
        "    self.west = None\n",
        "    self.south = None\n",
        "    # list of items - there's one case where there can be more than one item but its useful\n",
        "    self.items = []\n",
        "    # description of the room\n",
        "    self.desc = None\n",
        "    # bool as to whether a riddle can occur in the room\n",
        "    self.riddle = False\n",
        "    # message that the parser reads if the way is blocked.\n",
        "    self.blocked_msg = None"
      ],
      "metadata": {
        "id": "nKl9Rk91P9rd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basicest map\n",
        "start = Location()\n",
        "hallway = Location()\n",
        "candleRoom = Location()\n",
        "bugRoom = Location(True)\n",
        "escapeRoom = Location()\n",
        "\n",
        "# Joining up the locations\n",
        "start.east = hallway\n",
        "\n",
        "hallway.east = candleRoom\n",
        "hallway.west = start\n",
        "hallway.south = bugRoom\n",
        "\n",
        "candleRoom.west = hallway\n",
        "\n",
        "bugRoom.north = hallway\n",
        "bugRoom.south = escapeRoom\n",
        "\n",
        "escapeRoom.north = bugRoom\n",
        "\n",
        "# Set items in the rooms\n",
        "candleRoom.items.append(\"candle\")\n",
        "hallway.items.append(\"rocks\")\n",
        "\n",
        "# Establishes the rooms the riddles will occur in\n",
        "start.riddle = True\n",
        "candleRoom.riddle = True\n",
        "escapeRoom.riddle = True\n",
        "\n",
        "# Set descriptions for the room\n",
        "start.desc = \"\"\"A dim room in the stone temple. You woke up here. It smells like mold and is too dark to make much out.\n",
        "You're pretty sure you've seen Indiana Jones in a place like this.\n",
        "Only he had a gun.\"\"\"\n",
        "\n",
        "hallway.desc = \"\"\"A room that connects to three others.\n",
        "This had to be the ancient equivalent of a hallway?\n",
        "There was a fourth door at one point but all that stands in its place is a pile of rubble.\n",
        "The room to East looks surprisisngly bright.\n",
        "Echoes carry in from the South room.\"\"\"\n",
        "\n",
        "candleRoom.desc = \"\"\"A surprisingly bright room. It takes your eyes some time to adjust.\n",
        "Candles line the walls, still lit despite nobody living here.\n",
        "You almost forget how hot it is until you feel a bead of sweat rolling down your face.\"\"\"\n",
        "\n",
        "bugRoom.desc = \"\"\"The echo you heard grows louder and louder until you're face to face with its source.\n",
        "Bugs. Cockroaches, centipedes, spiders. They scuttle about the darkness.\n",
        "You can't even see the tiles you're standing on.\n",
        "Just past the buzzing you can see light - daylight even.\"\"\"\n",
        "\n",
        "escapeRoom.desc = \"\"\"You can just barely see the daylight! You're nearly freed.\n",
        "'escape' to free yourself!\n",
        "\"\"\"\n",
        "\n",
        "# Set block messages to the room\n",
        "bugRoom.blocked_msg = \"You take a few steps into the bug infested room only for something to sink its teeth into you. Then another bite. You quickly run back,\"\n",
        "escapeRoom.blocked_msg = \"You cannot leave. The Sphinx won't let you.\""
      ],
      "metadata": {
        "id": "8pWrr8DxRn7o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parser class"
      ],
      "metadata": {
        "id": "hL_jWcISEdwv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "33PzUkp3DP-F"
      },
      "outputs": [],
      "source": [
        "class Parser:\n",
        "  def __init__(self, debug = False):\n",
        "    self.lives = 3\n",
        "    self.location = start\n",
        "    self.inventory = []\n",
        "    self.level = 0\n",
        "    self.victory = False\n",
        "    self.debug = debug\n",
        "    self.explanation = None\n",
        "\n",
        "  def comp(self, response, answer):\n",
        "      # answer - compares the response given to the answer the model provided.\n",
        "      #\n",
        "      # inputs: user response and the answer given by the llm\n",
        "      # returns: True or False\n",
        "      # True - the answer is correct, it passes the threshold\n",
        "      # False - the answer is incorrect.\n",
        "\n",
        "\n",
        "      # tokenize\n",
        "      resp_tokens = response.lower().split()\n",
        "      ans_tokens = answer.lower().split()\n",
        "\n",
        "      # build frequency dicts\n",
        "      resp_vec = {}\n",
        "      for w in resp_tokens:\n",
        "        resp_vec[w] = resp_vec.get(w, 0) + 1\n",
        "\n",
        "      ans_vec = {}\n",
        "      for w in ans_tokens:\n",
        "        ans_vec[w] = ans_vec.get(w, 0) + 1\n",
        "\n",
        "      # vocabulary\n",
        "      all_words = set(resp_vec.keys()) | set(ans_vec.keys())\n",
        "\n",
        "      # numeric vectors\n",
        "      v1 = [resp_vec.get(w, 0) for w in all_words]\n",
        "      v2 = [ans_vec.get(w, 0) for w in all_words]\n",
        "\n",
        "      # cosine similarity\n",
        "      dot = sum(a * b for a, b in zip(v1, v2))\n",
        "      mag1 = math.sqrt(sum(a * a for a in v1))\n",
        "      mag2 = math.sqrt(sum(b * b for b in v2))\n",
        "\n",
        "      cosine_sim = 0 if (mag1 == 0 or mag2 == 0) else dot / (mag1 * mag2)\n",
        "\n",
        "      # threshold check\n",
        "      return True if cosine_sim >= 0.4 else False\n",
        "\n",
        "      return True if eval >= 0.4 else False # thresholds the % match of the\n",
        "\n",
        "  def ask(self):\n",
        "    # promtpts the LLM to output a new riddle in the form of a json file\n",
        "    # that includes the riddle, a hint and the answer. The function runs a nested loop that\n",
        "    # checks users answer to give you multiple tries.\n",
        "    #\n",
        "    #\n",
        "    # inputs : None\n",
        "    # output : True if the question was correctly answered, False if not.\n",
        "\n",
        "    # Input prompt\n",
        "    myInput = \"\"\"Your job is to generate a riddle given another riddle. Only send the riddle and answer. Following is an example of a riddle you should emulate. Example: \"\"\" + getExample()\n",
        "    minimenu = \"\"\"You may 'give up' and get another question\\nSometimes the Sphinx is stupid. Say 'what' when its stupid.\\nYour answer: \"\"\"\n",
        "\n",
        "\n",
        "    # Generate text\n",
        "    modelOutput = promptMinstral(myInput)\n",
        "    self.explanation = modelOutput\n",
        "\n",
        "    # Decode and print the output\n",
        "    gameriddle, gameanswer = decodeOutput(modelOutput)\n",
        "\n",
        "    riddle_loop = True\n",
        "    while riddle_loop and self.lives > 0: # different from the gameloop, riddle loop, consists only of the sphinx's question and answering.\n",
        "      if self.level == 0:\n",
        "        print(\"The sphinx lunges forward, ready to pounce on you. You see your life flash before your eyes before it asks,\\n\\\"\"+ gameriddle + \"\\\"\")\n",
        "      if self.level == 1:\n",
        "        print(\"You're unsure of when the sphinx cornered you but you know what comes next. It bares its fangs this time and snarls out,\\n\\\"\"+ gameriddle + \"\\\"\")\n",
        "      if self.level == 0:\n",
        "        print(\"You've never seen eyes with such murderous intent. The beast wants you dead. And you want out. End this here.\\n\\\"\"+ gameriddle + \"\\\"\")\n",
        "      if self.debug:\n",
        "        print(\"======================================================\")\n",
        "        print(\"BACKEND DETAILS: \")\n",
        "        print(modelOutput)\n",
        "        print(gameriddle)\n",
        "        print(gameanswer)\n",
        "        print(\"======================================================\")\n",
        "\n",
        "      response = input(minimenu)\n",
        "      response = response.lower()\n",
        "      responseList = response.split(\" \")\n",
        "\n",
        "\n",
        "      if gameanswer == \"None\":\n",
        "        print(\"The sphinx has a stroke and forgot to think of an answer to its own riddle. It's your lucky day\")\n",
        "        self.location.riddle = False\n",
        "        return True\n",
        "      if responseList[0] == 'give' and responseList[1] == 'up':\n",
        "        print(\"Try as you might, you can't figure this one out. The sphinx claws at you for your incompetence, costing you dearly.\")\n",
        "        print(\"The answer the sphinx wanted was: \" + gameanswer)\n",
        "        self.lives -= 1\n",
        "        return False\n",
        "      elif responseList[0] == 'what':\n",
        "        print(\"The sphinx's old age is clearly getting to it. You fail to understand the question and it gets really embarassed\\nLike she's blushing and everything.\\nIt leaves you for now...\")\n",
        "        print(\"The answer the sphinx wanted was: \" + gameanswer)\n",
        "        self.location.riddle = False\n",
        "        return True\n",
        "      if self.comp(response, gameanswer):\n",
        "        print(\"That was correct.\")\n",
        "        print(\"The sphinx looks annoyed but it sulks off in defeat.\")\n",
        "        self.location.riddle = False\n",
        "        print(\"From nowhere \" + gameanswer + \"drops to the floor from above. You can't see where it came from but it looks useful\")\n",
        "        self.location.items.append(gameanswer)\n",
        "        return True\n",
        "      else:\n",
        "        print(\"The sphinx makes a noise like laughter. Then it swipes at you! Her claws cut your skin, leaving a nasty gash.\\nYou were wrong. One step closer to being sealed inside forever.\")\n",
        "        self.lives -= 1\n",
        "\n",
        "    # case where you failed the riddle and died.\n",
        "    print(\"You try for an answer but it's too late. You've ran out of guesses. The beast lunges at you and sinks its teeth in. In an instant you're devoured.\")\n",
        "    print(\"The answer the sphinx wanted was: \" + gameanswer)\n",
        "    return False\n",
        "\n",
        "  def prologue(self):\n",
        "    # Prologue -\n",
        "    # returns nothing but easier to navigate than multiple strings\n",
        "\n",
        "    # Updates things that should change during the game\n",
        "    self.lives = 3\n",
        "    self.location = start\n",
        "    self.inventory = []\n",
        "    self.level = 0\n",
        "    self.victory = False\n",
        "    bugRoom.desc =  \"\"\"The echo you heard grows louder and louder until you're face to face with its source.\n",
        "Bugs. Cockroaches, centipedes, spiders. They scuttle about the darkness.\n",
        "You can't even see the tiles you're standing on.\n",
        "Just past the buzzing you can see light - daylight even.\"\"\"\n",
        "\n",
        "    start.riddle = True\n",
        "    candleRoom.riddle = True\n",
        "    escapeRoom.riddle = True\n",
        "    bugRoom.blocked = True\n",
        "    escapeRoom.blockked = True\n",
        "    candleRoom.items = [\"candle\"]\n",
        "    hallway.items =[\"rocks\"]\n",
        "\n",
        "\n",
        "    print(\"\"\"\\nâ–€â–ˆâ–€ â–ˆâ–€â–ˆ â–ˆ â–„â–€â–ˆ â–ˆâ–‘â–‘ â€ƒ â–ˆâ–€â–ˆ â–ˆâ–€â–€ â€ƒ â–€â–ˆâ–€ â–ˆâ–‘â–ˆ â–ˆâ–€â–€ â€ƒ â–ˆâ–€ â–ˆâ–€â–ˆ â–ˆâ–‘â–ˆ â–ˆ â–ˆâ–„â–‘â–ˆ â–€â–„â–€\n",
        "â–‘â–ˆâ–‘ â–ˆâ–€â–„ â–ˆ â–ˆâ–€â–ˆ â–ˆâ–„â–„ â€ƒ â–ˆâ–„â–ˆ â–ˆâ–€â–‘ â€ƒ â–‘â–ˆâ–‘ â–ˆâ–€â–ˆ â–ˆâ–ˆâ–„ â€ƒ â–„â–ˆ â–ˆâ–€â–€ â–ˆâ–€â–ˆ â–ˆ â–ˆâ–‘â–€â–ˆ â–ˆâ–‘â–ˆ\n",
        "\n",
        "You were out on an expedition. All it was supposed to be was a quick trip to\n",
        "a nearby 'temple.' Well, it was more of a tourist trap. You were pretty sure\n",
        "anyway. The photos you'd seen looked plastic and from there wasn't a thing in\n",
        "sight that couldn't have been bought off Amazon. You climbed stone stairs\n",
        "through a forest to get here -\n",
        "\n",
        "Then you slipped.\n",
        "\n",
        "You wake up in a completely unfamilliar room. Your cheek was red, imprinted with\n",
        "the stone flooring you'd been up against for the last several hours. The whole\n",
        "room dark, creepy - and worst of all real.\n",
        "\n",
        "\"To leave,\" you hear a voice start. \"You must first answer my Riddles Three.\"\n",
        "Out from the darkness a sphinx slinks forward. Not the stone faced sculpture\n",
        "you've seen in photos but a real sphinx. Its a menacing beast with the body\n",
        "of a lion, wings and the face of an old lady.\n",
        "\n",
        "\\\"You're a fool for coming here\\\" She snarls, \\\"and I'm never letting you leave.\\\"\\n\"\"\")\n",
        "\n",
        "  def game(self):\n",
        "    # Game - Provides the game loop and main functionality of the game.\n",
        "    # The game ends when the player quits, runs out of lives or they\n",
        "    # correctly respond to three riddles.\n",
        "\n",
        "    playing = True\n",
        "\n",
        "    self.prologue()\n",
        "\n",
        "    while(playing and self.lives > 0 and not self.victory): # GAMELOOP\n",
        "\n",
        "      # Room message.\n",
        "      print(self.location.desc+'/n')\n",
        "      if(self.location.blocked):\n",
        "        print(\"You aren't be able to go any further south at this time.\")\n",
        "      if self.location.riddle:\n",
        "        print(\"Out from the shadows, the sphinx moves in front of the door. You must 'play' her game to pass.\")\n",
        "\n",
        "      # Takes user response and splits it before going through commands\n",
        "      response = input(\"\")\n",
        "      response = response.lower()\n",
        "      responseList = response.split(\" \")\n",
        "\n",
        "      # the big switch case controlling our game.\n",
        "      if(responseList[0] == \"q\" or responseList[0] == \"quit\"):\n",
        "        playing = False # User ends the game on their own, it ends here\n",
        "\n",
        "      # plays - enters the riddle.\n",
        "      elif(responseList[0] == 'play'):\n",
        "        if self.location.riddle:\n",
        "          if self.ask():\n",
        "            self.level+=1\n",
        "            print(\"Your chest swells with pride over your victory.\")\n",
        "          else:\n",
        "            print(\"You failed the sphinx's riddle!\")\n",
        "        else:\n",
        "          print(\"The sphinx is not in this room.\")\n",
        "\n",
        "      # Directional controls for the location system.\n",
        "      elif(responseList[0] == \"n\" or responseList[0] == \"north\"):\n",
        "          if self.location.north:\n",
        "            if not self.location.riddle or self.debug:\n",
        "                self.location = self.location.north\n",
        "            else:\n",
        "              print(\"The sphinx has you trapped in this room until you can answer her riddle!\")\n",
        "          else: print(\"There is no north exit.\")\n",
        "      elif(responseList[0] == \"e\" or responseList[0] == \"east\"):\n",
        "          if self.location.east:\n",
        "            if not self.location.riddle or self.debug:\n",
        "              self.location = self.location.east\n",
        "            else:\n",
        "              print(\"The sphinx has you trapped in this room until you can answer her riddle!\")\n",
        "          else: print(\"There is no east exit.\")\n",
        "      elif(responseList[0] == \"w\" or responseList[0] == \"west\"):\n",
        "          if self.location.west:\n",
        "            if not self.location.riddle or self.debug:\n",
        "              self.location = self.location.west\n",
        "            else:\n",
        "              print(\"The sphinx has you trapped in this room until you can answer her riddle!\")\n",
        "          else: print(\"There is no west exit.\")\n",
        "      elif(responseList[0] == \"s\" or responseList[0] == \"south\"):\n",
        "        if self.location.south:\n",
        "          if not self.location.blocked: # Progress will only ever go south, so we only need to check if its blocked here\n",
        "              if not self.location.riddle or self.debug: # checks if in debug mode or if you've finished the riddle\n",
        "               self.location = self.location.south\n",
        "              else:\n",
        "                print(\"The sphinx has you trapped in this room until you can answer her riddle!\")\n",
        "          else:\n",
        "            print(self.location.blocked_msg)\n",
        "        else: print(\"There is no south exit.\")\n",
        "\n",
        "      # give up command - going to phase out as we'll move the riddles to the ask function\n",
        "      elif(responseList[0] == \"give\" and responseList[1] == \"up\"):\n",
        "         print(\"You succumb to despair, losing a life\")\n",
        "         self.lives -= 1\n",
        "\n",
        "      # why - why'd you get that last answer right?\n",
        "      elif(responseList[0] == \"why\"):\n",
        "        if self.explanation:\n",
        "          print(self.explanation)\n",
        "        else:\n",
        "          print(\"Why what?\")\n",
        "\n",
        "      # look around - checks all exits\n",
        "      elif(responseList[0] == \"look\"):\n",
        "        if self.location.north:\n",
        "          print(\"There is an exit to the north\")\n",
        "        if self.location.east:\n",
        "          print(\"There is an exit to the east\")\n",
        "        if self.location.west:\n",
        "          print(\"There is an exit to the west\")\n",
        "        if self.location.south:\n",
        "          print(\"There is an exit to the south\")\n",
        "        if(self.location.blocked):\n",
        "          print(\"You are won't be able to go south. Something is blocking the way. Probably bugs. Maybe scare them off with something hot?\")\n",
        "        if self.location.riddle:\n",
        "          print(\"The sphinx is in this room, stopping you from leaving until you best it at its own game. Which is stupid. You wish you could play your own game instead.\")\n",
        "        if (self.location.items): # If there are items they're listed\n",
        "          print(\"You see something useful: \")\n",
        "          for item in self.location.items:\n",
        "            print(\"\\t a \" + item)\n",
        "\n",
        "      # get - it allows players to\n",
        "      elif(responseList[0] == \"get\"):\n",
        "        if self.location.items:\n",
        "          print(\"You pickup the following items: \" + str(self.location.items))\n",
        "          self.inventory = self.inventory + self.location.items # conjoins the lists\n",
        "          self.location.items = [] # empties out the list of items\n",
        "        else:\n",
        "          print(\"Have you gone mad already? There's nothing there.\")\n",
        "\n",
        "      # light - our main text based puzzle - players light up their candle to unblock the bug room\n",
        "      elif(responseList[0] == \"light\" or \"fire\" in responseList):\n",
        "        if \"candle\" or \"wood\" in self.inventory:\n",
        "          if self.location == bugRoom:\n",
        "            if \"rocks\" in self.inventory:\n",
        "              print(\"You channel your inner caveman and start a fire. The bugs scurry away, leaving you free to head south in peace.\")\n",
        "              bugRoom.blocked = False\n",
        "              bugRoom.desc = \"\"\"Now that those pesky insects are gone you're free to roam the room. It smells like spilled ice cream. Maybe that's why there were all those bugs?\\nThe room to the north is the hallway. Why head back though?\\nTo the south is your escape. Now closer than ever\"\"\"\n",
        "              self.inventory.remove(\"candle\")\n",
        "              self.inventory.remove(\"rocks\")\n",
        "            else:\n",
        "              print(\"You rub your hands together to no avail. Unfortunately starting a fire takes some type of lighter... Drat, you left that at home.\")\n",
        "          else:\n",
        "            print(\"There's no reason to do that here.\")\n",
        "        else:\n",
        "          print(\"Despite your attempts to start a fire with your mind you have nothing to set ablaze\")\n",
        "      # escape - Win the game if sphinx doesn't have you in for a riddle\n",
        "      elif(responseList[0] == \"escape\"):\n",
        "        if self.location==escapeRoom and not self.location.riddle:\n",
        "          print(\"You bust through a nearby wall into the open air! You've defeated the sphinx and now you're free!\")\n",
        "          if len(self.inventory) > 0:\n",
        "            print(\"Along the way you got some loot!\")\n",
        "            for item in self.inventory:\n",
        "              print(\"\\t You won a\" + item)\n",
        "          self.victory = True\n",
        "        if self.debug:\n",
        "          print(\"You win through your amazing cheating skills\")\n",
        "          self.victory = True\n",
        "      elif(responseList[0] == \"inventory\"):\n",
        "        print(\"You look over the items you somehow fit in your pocket. You've got:\")\n",
        "        if len(self.inventory) > 0:\n",
        "          for item in self.inventory:\n",
        "              print(\"\\t You won a\" + item)\n",
        "\n",
        "      # help gives the controls\n",
        "      elif(responseList[0] == \"help\" or responseList[0] == \"h\"):\n",
        "        print(\"Controls :\")\n",
        "        print(\"\\t\" +\"play - In rooms where the sphinx lurks you can play its game. It won't let you go until you answer correctly.\")\n",
        "        print(\"\\t\" +\"why - after being asked a riddle and answering successfully you can hear the sphinx's explanation of the riddle.\")\n",
        "        print(\"\\t\" + \"q/quit - exits out of the game\")\n",
        "\n",
        "        print(\"\\t\" +\"Directions: \")\n",
        "        print(\"\\t\" + \"\\t\" + \"n/north - moves to the room north of this one\")\n",
        "        print(\"\\t\" + \"\\t\" + \"e/east - moves to the room east of this one\")\n",
        "        print(\"\\t\" + \"\\t\" + \"s/south - moves to the room south of this one\")\n",
        "        print(\"\\t\" + \"\\t\" + \"w/west - moves to the room west of this one\")\n",
        "\n",
        "        print(\"\\t\" +\"look - describes the room's exits, blockages and any items in it. Very useful\")\n",
        "        print(\"\\t\" +\"inventory - shows you the items you've obtained\")\n",
        "        print(\"\\t\" +\"get - adds all items in a room to your inventory.\")\n",
        "        print(\"\\t\" +\"There are more commands related to any items you might find! Try things out!\")\n",
        "\n",
        "      # else - the player misinput\n",
        "      else:\n",
        "        print(\"Not a registered command. Please type 'help' for a list of all controls.\")\n",
        "\n",
        "\n",
        "    # The gameloop has ended.\n",
        "    if self.victory:\n",
        "      print(\"\"\"Congratulations! You're free from the sphinx's game and did not meet a fate most gruesome.\n",
        "      You spend the next several hours trying to remember where you parked.\n",
        "      Thanks for playing!\n",
        "      â–ˆâ–‘â–ˆâ–‘â–ˆ â–ˆ â–ˆâ–„â–‘â–ˆ â–ˆâ–„â–‘â–ˆ â–ˆâ–€â–€ â–ˆâ–€â–ˆ\n",
        "      â–€â–„â–€â–„â–€ â–ˆ â–ˆâ–‘â–€â–ˆ â–ˆâ–‘â–€â–ˆ â–ˆâ–ˆâ–„ â–ˆâ–€â–„\n",
        "\"\"\")\n",
        "    else:\n",
        "      if self.lives >= 0:\n",
        "        print(\"Your adventure ends here. Your heart comes to a sudden stop.\")\n",
        "      print(\"The tomb seals shut, dooming you to spend the rest of your short life within this miserable pit.\")\n",
        "      print(\"\"\"â–ˆâ–‘â–ˆâ–‘â–ˆ â–ˆâ–€â–ˆ â–ˆâ–€â–„â–€â–ˆ â–ˆâ–€â–ˆ â€ƒ â–ˆâ–‘â–ˆâ–‘â–ˆ â–ˆâ–€â–ˆ â–ˆâ–€â–„â–€â–ˆ â–ˆâ–€â–ˆ\n",
        "â–€â–„â–€â–„â–€ â–ˆâ–„â–ˆ â–ˆâ–‘â–€â–‘â–ˆ â–ˆâ–€â–€ â€ƒ â–€â–„â–€â–„â–€ â–ˆâ–„â–ˆ â–ˆâ–‘â–€â–‘â–ˆ â–ˆâ–€â–€\"\"\")\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pharohs_game = Parser(True)\n",
        "pharohs_game.game()"
      ],
      "metadata": {
        "id": "zBH4sT6yVHNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a724f6c-948c-4e2c-e8c2-021b1002f2a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â–€â–ˆâ–€ â–ˆâ–€â–ˆ â–ˆ â–„â–€â–ˆ â–ˆâ–‘â–‘ â€ƒ â–ˆâ–€â–ˆ â–ˆâ–€â–€ â€ƒ â–€â–ˆâ–€ â–ˆâ–‘â–ˆ â–ˆâ–€â–€ â€ƒ â–ˆâ–€ â–ˆâ–€â–ˆ â–ˆâ–‘â–ˆ â–ˆ â–ˆâ–„â–‘â–ˆ â–€â–„â–€\n",
            "â–‘â–ˆâ–‘ â–ˆâ–€â–„ â–ˆ â–ˆâ–€â–ˆ â–ˆâ–„â–„ â€ƒ â–ˆâ–„â–ˆ â–ˆâ–€â–‘ â€ƒ â–‘â–ˆâ–‘ â–ˆâ–€â–ˆ â–ˆâ–ˆâ–„ â€ƒ â–„â–ˆ â–ˆâ–€â–€ â–ˆâ–€â–ˆ â–ˆ â–ˆâ–‘â–€â–ˆ â–ˆâ–‘â–ˆ\n",
            "\n",
            "You were out on an expedition. All it was supposed to be was a quick trip to\n",
            "a nearby 'temple.' Well, it was more of a tourist trap. You were pretty sure\n",
            "anyway. The photos you'd seen looked plastic and from there wasn't a thing in\n",
            "sight that couldn't have been bought off Amazon. You climbed stone stairs\n",
            "through a forest to get here -\n",
            "\n",
            "Then you slipped.\n",
            "\n",
            "You wake up in a completely unfamilliar room. Your cheek was red, imprinted with\n",
            "the stone flooring you'd been up against for the last several hours. The whole\n",
            "room dark, creepy - and worst of all real.\n",
            "\n",
            "\"To leave,\" you hear a voice start. \"You must first answer my Riddles Three.\"\n",
            "Out from the darkness a sphinx slinks forward. Not the stone faced sculpture\n",
            "you've seen in photos but a real sphinx. Its a menacing beast with the body\n",
            "of a lion, wings and the face of an old lady.\n",
            "\n",
            "\"You're a fool for coming here\" She snarls, \"and I'm never letting you leave.\"\n",
            "\n",
            "A dim room in the stone temple. You woke up here. It smells like mold and is too dark to make much out.\n",
            "You're pretty sure you've seen Indiana Jones in a place like this.\n",
            "Only he had a gun./n\n",
            "Out from the shadows, the sphinx moves in front of the door. You must 'play' her game to pass.\n",
            "e\n",
            "A room that connects to three others.\n",
            "This had to be the ancient equivalent of a hallway?\n",
            "There was a fourth door at one point but all that stands in its place is a pile of rubble.\n",
            "The room to East looks surprisisngly bright.\n",
            "Echoes carry in from the South room./n\n",
            "get\n",
            "You pickup the following items: ['rocks']\n",
            "A room that connects to three others.\n",
            "This had to be the ancient equivalent of a hallway?\n",
            "There was a fourth door at one point but all that stands in its place is a pile of rubble.\n",
            "The room to East looks surprisisngly bright.\n",
            "Echoes carry in from the South room./n\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3094167340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpharohs_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpharohs_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1003496423.py\u001b[0m in \u001b[0;36mgame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0;31m# Takes user response and splits it before going through commands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0mresponseList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}